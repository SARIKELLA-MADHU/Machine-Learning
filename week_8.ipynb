{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOs+V+uh+itaAZwVXpLIwgp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SARIKELLA-MADHU/Machine-Learning/blob/main/week_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "733LM1Qs_98U",
        "outputId": "583cbec2-42fd-4f16-8eea-3f846b22a24d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: (0.82, 0.7428571428571429, 0.896551724137931, 0.8125)\n",
            "Random Forest: (0.855, 0.7843137254901961, 0.9195402298850575, 0.8465608465608465)\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree vs Random Forest Comparison\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=6, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Single Classifier: Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Ensemble Classifier: Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "metrics = lambda y_true, y_pred: (\n",
        "    accuracy_score(y_true, y_pred),\n",
        "    precision_score(y_true, y_pred),\n",
        "    recall_score(y_true, y_pred),\n",
        "    f1_score(y_true, y_pred)\n",
        ")\n",
        "\n",
        "dt_results = metrics(y_test, y_pred_dt)\n",
        "rf_results = metrics(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Decision Tree:\", dt_results)\n",
        "print(\"Random Forest:\", rf_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Max, Average, and Weighted Voting\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Base models\n",
        "model1 = LogisticRegression(max_iter=200)\n",
        "model2 = DecisionTreeClassifier()\n",
        "model3 = SVC(probability=True)\n",
        "\n",
        "# Simple Ensemble Techniques\n",
        "max_voting = VotingClassifier(estimators=[\n",
        "    ('lr', model1), ('dt', model2), ('svc', model3)\n",
        "], voting='hard')\n",
        "\n",
        "avg_voting = VotingClassifier(estimators=[\n",
        "    ('lr', model1), ('dt', model2), ('svc', model3)\n",
        "], voting='soft')\n",
        "\n",
        "max_voting.fit(X_train, y_train)\n",
        "avg_voting.fit(X_train, y_train)\n",
        "\n",
        "# Weighted Voting (weights assigned by model accuracy)\n",
        "model1.fit(X_train, y_train)\n",
        "model2.fit(X_train, y_train)\n",
        "model3.fit(X_train, y_train)\n",
        "wts = [\n",
        "    model1.score(X_test, y_test),\n",
        "    model2.score(X_test, y_test),\n",
        "    model3.score(X_test, y_test)\n",
        "]\n",
        "weighted_voting = VotingClassifier(\n",
        "    estimators=[('lr', model1), ('dt', model2), ('svc', model3)],\n",
        "    voting='soft', weights=wts\n",
        ")\n",
        "weighted_voting.fit(X_train, y_train)\n",
        "\n",
        "# Accuracy Comparison\n",
        "print(\"Max Voting Accuracy:\", accuracy_score(y_test, max_voting.predict(X_test)))\n",
        "print(\"Average Voting Accuracy:\", accuracy_score(y_test, avg_voting.predict(X_test)))\n",
        "print(\"Weighted Voting Accuracy:\", accuracy_score(y_test, weighted_voting.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL4_d8bkAHlm",
        "outputId": "57b6b2c1-0990-4f3a-c756-65f2eab4cf9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Voting Accuracy: 1.0\n",
            "Average Voting Accuracy: 1.0\n",
            "Weighted Voting Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hard vs Soft Voting Comparison\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris.data, iris.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Base models\n",
        "estimator = [\n",
        "    ('LR', LogisticRegression(max_iter=200)),\n",
        "    ('SVC', SVC(probability=True)),\n",
        "    ('DTC', DecisionTreeClassifier())\n",
        "]\n",
        "\n",
        "hard_voting = VotingClassifier(estimators=estimator, voting='hard')\n",
        "soft_voting = VotingClassifier(estimators=estimator, voting='soft')\n",
        "\n",
        "hard_voting.fit(X_train, y_train)\n",
        "soft_voting.fit(X_train, y_train)\n",
        "\n",
        "print(\"Hard Voting Accuracy:\", accuracy_score(y_test, hard_voting.predict(X_test)))\n",
        "print(\"Soft Voting Accuracy:\", accuracy_score(y_test, soft_voting.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAuFuxpzAKe2",
        "outputId": "9b2fec77-35b8-4bd1-90aa-8a7b18a3c714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hard Voting Accuracy: 1.0\n",
            "Soft Voting Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring Bagging using Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=6, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "for n in [10, 50, 100]:\n",
        "    rf = RandomForestClassifier(n_estimators=n, max_depth=None, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    acc = accuracy_score(y_test, rf.predict(X_test))\n",
        "    print(f\"Estimators={n}, Accuracy={acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZc-nXUaAQv2",
        "outputId": "9a7252d1-fa33-4707-ee1c-c52d33e4e65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimators=10, Accuracy=0.825\n",
            "Estimators=50, Accuracy=0.850\n",
            "Estimators=100, Accuracy=0.855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestRegressor with Out-of-Bag (OOB) Score\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Dataset\n",
        "data = load_diabetes()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Model\n",
        "rf = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Evaluation\n",
        "pred = rf.predict(X)\n",
        "print(\"OOB Score:\", rf.oob_score_)\n",
        "print(\"MSE:\", mean_squared_error(y, pred))\n",
        "print(\"R2 Score:\", r2_score(y, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jPiXMQcAM32",
        "outputId": "9891706c-c1a5-4888-d302-2451ddef5e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.4205759837575107\n",
            "MSE: 476.8155608597285\n",
            "R2 Score: 0.9195910933940452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoost, Gradient Boosting, XGBoost, CatBoost\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. AdaBoost\n",
        "ada = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "ada.fit(X_train, y_train)\n",
        "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, ada.predict(X_test)))\n",
        "\n",
        "# 2. Gradient Boosting\n",
        "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gb.predict(X_test)))\n",
        "\n",
        "# 3. XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo38gGx9AWqS",
        "outputId": "e1c74a8b-0e31-47d6-df5d-efbf486195f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Accuracy: 0.85\n",
            "Gradient Boosting Accuracy: 0.93\n",
            "XGBoost Accuracy: 0.925\n"
          ]
        }
      ]
    }
  ]
}